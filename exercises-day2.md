The goal of Day 2 exercises is to phase a triploid yeast genome, CBS1483 and assemble the haplotypes. Then we will evaluate and visualize the haplotype-phased assemblies. For phasing, we will use [`HAT`](https://github.com/AbeelLab/hat) and [`nPhase`](https://github.com/OmarOakheart/nPhase).

First we need to get started with the practical environment: download the zipped file titled `data-day2.tar.gz`, this contains the data and the `conda` environment that we will use in exercises today. We need to extract them.

#### Task: Get started

- Extract the contents of `data-day2.tar.gz`. You should have two new tarballs titled `reads-day2.tar.gz` and `vlpb2-conda.tar.gz`
- Create a directory titled `vlpb2` and extract the contents of `vlp2-conda.tar.gz` into this directory. We will be using this `conda` environment today.

```bash
mkdir vlpb2
tar -xzf vlpb2-conda.tar.gz -C vlpb2
cd vlpb2
conda activate
conda-unpack
cd ..
```

- Extract the data files for day 2 (`data2.tar.gz`). 

```bash
tar -xzvf data2.tar.gz
```

#### Task: Explore the project directory

- In the beginning, your project directory should have the subdirectory titled `reads` where the input reads we will phase before assembling them are stored. In this directory you will find the paired end short reads (`shortreads_p1.fastq` and `shortreads_p2.fastq`) and the long reads (`longreads.fastq`). You should create new directories to store the phasing and assembly outputs. 

```bash
mkdir phasing assembly
```

#### Task: Explore the reads and calculate read statistics

- Before we begin, make sure you have the `vlpb2` environment activated.

```bash
conda activate vlpb2
```

- We will use `NanoPlot` to calculate read statistics and visualize them, we will create an `html` report.

```bash
NanoPlot --fastq <input file> -o <output directory> --plots hex dot kde
```

You should replace `<input file>` with 3 `fastq` files stored in `reads`: `shortreads1.fastq`, `shortreads2.fastq` and `longreads.fastq`. And you can use the `reads` directory to store the outputs.

*HINT: Use the `html` output generated by `NanoPlot`*

#### Task: Preprocess reads

- Filter the long reads to remove reads shorter than 1kbp. Use `filtlong`

```bash
filtlong --min_length 10000 longreads.fastq > longreads_filtered.fastq
```

#### Task: Run HAT

- First let's create a directory to store the HAT phasing outputs

```bash
mkdir phasing/hat
```

- To run HAT, we need the following 3 input files
	- Sorted bam file from the alignment of short reads to the reference genome
	- Sorted bam file from the alignment of long reads to the reference genome
	- SNPs selected from a VCF file created by any variant calling tool.
    
- Let's map the short reads to the reference genome (`bwa mem`) and call variants (`FreeBayes`).

```bash
# Index the reference sequence
bwa index data/reference/reference_scI_CP048983.1.fasta
# Map short reads tot he reference sequence
bwa mem -t 2 data/reference/reference_scI_CP048983.1.fasta data/reads/shortreads1.fastq data/reads/shortreads2.fastq > phasing/hat/shortreads_aln.sam
# Convert sam alignment to bam format
samtools view -bS -q 35 phasing/hat/shortreads_aln.sam > phasing/hat/shortreads_aln.bam
# Sort and index the bam alignment
samtools sort --threads 2 phasing/hat/shortreads_aln.bam -o phasing/hat/shortreads_aln.sorted.bam
samtools index phasing/hat/shortreads_aln.sorted.bam
# Call variants
freebayes -f data/reference/reference_scI_CP048983.1.fasta phasing/hat/shortreads_aln.sorted.bam --ploidy 3 > phasing/hat/var.vcf
# Extract only the SNPS from the vcf output
vcffilter -f "TYPE = snp" phasing/hat/var.vcf > phasing/hat/snp-var.vcf
bgzip -c phasing/hat/snp-var.vcf > phasing/hat/snp-var.vcf.gz
```

- Let's align the long reads to the reference genome (`minimap2`)
```bash
minimap2 -ax map-ont --secondary=no data/reference/reference_scI_CP048983.1.fasta data/reads/longreads_filtered.fastq > phasing/hat/longreads_aln.sam
# Convert the alignment to bam format and sort
samtools view -bS -q 35 phasing/hat/longreads_aln.sam > phasing/hat/longreads_aln.bam
# Sort and index the bam alignment
samtools sort --threads 2 phasing/hat/longreads_aln.bam -o phasing/hat/longreads_aln.sorted.bam
samtools index phasing/hat/longreads_aln.sorted.bam
```

- Now we can run HAT with the parameter `-ha`. When we use the `-ha` option, HAT will assemble the clustered reads into separate haplotypes all in one command. 

```bash
usage: HAT [-h] [-rl READ_LENGTH] [-pl PHASING_LOCATION] [-r REFERENCE_FILE] [-lf LONGREADS_FASTA]
           [-sf1 SHORTREADS_1_FASTQ] [-sf2 SHORTREADS_2_FASTQ] [-th TRUE_HAPLOTYPES]
           [-ma MULTIPLE_GENOME_ALIGNMENT] [-ha HAPLOTYPE_ASSEMBLY]
           chromosome_name vcf_file short_read_alignment long_read_alignment ploidy output output_dir
```

```bash
HAT -r data/reference/reference_scI_CP048983.1.fasta -ha True -lf data/reads/longreads_filtered.fastq -sf1 data/reads/shortreads1.fastq -sf2 data/reads/shortreads2.fastq CP048983.1 phasing/hat/snp-var.vcf.gz phasing/hat/shortreads_aln.sorted.bam phasing/hat/longreads_aln.sorted.bam 3 scI phasing/hat
```
#### Because it takes a while for HAT to run on a laptop, you can cancel the command you just ran (press `Ctrl+C`) and you do not have to wait for the program to finish running. 
- Instead, you can find the phasing outputs I have generated by running HAT on TU Delft's HPC in `HAT-output.tar.gz`. The data file you had downloaded earlier today (`data-day2.tar.gz`) should include this file, simply untar it into the subdirectory we have created to store HAT outputs.
```bash
tar -xcvf HAT-output.tar.gz -C phasing/hat
```

#### Task: Run nPhase

- Create a directory to store the nPhase phasing outputs

```bash
mkdir phasing/nphase
```

- Now we can run the entire pipeline with a single command

```bash
nphase pipeline --sampleName scI --reference data/reference/reference_scI_CP048983.1.fasta --output phasing/nphase --longReads data/reads/longreads_filtered.fastq --longReadPlatform ont --R1 data/reads/shortreads1.fastq --R2 data/reads/shortreads2.fastq --threads 2
```
- After you run the pipeline, you should have the following output directories under `phasing/nphase`:

```
└── scI
    ├── Logs
    ├── Mapped
    ├── Overlaps
    ├── Phased
    ├── Readme.txt
    └── VariantCalls
```
- You will find six text files in the `Phased` folder. By default, `nPhase` will name each file with the prefix that includes the parameter values. In our example, the prefix is: `scI_0.1_0.01_0.05_0`. The `nPhase` github documentations explains these files as follows:
	- scI_0.1_0.01_0.05_0_variants.tsv: For each haplotig, the haplotig name, chromosome, position, base
	- scI_0.1_0.01_0.05_0_clusterReadNames.tsv: For each haplotig, the names of reads that comprise it
	- scI_0.1_0.01_0.05_0_phasedDataFull.tsv: For each haplotig, the position, chromosome, y position of each phased SNP. Raw data, not used to generate the phasedVis plot.
	- scI_0.1_0.01_0.05_0_discordanceVis.tsv: For each haplotig, the haplotig name, chromosome, position, base, frequency, coverage. Used to generate the discordanceVis plot.
	- scI_0.1_0.01_0.05_0_phasedDataSimple.tsv: For each haplotig, the start position, stop position, chromosome, y position. Used to generate the phasedVis plot.
	- scI_0.1_0.01_0.05_0_covVis.tsv: For each haplotig, the haplotig name, chromosome, 5kb window, mean coverage for the window
    
- We also have one `fastq` file for each haplotig predicted in `Phased/FastQ`, and the long reads that belong to them. We can use these long reads to assemble haplotypes separately. We will use `miniasm` for assembly, you can repeat the commands we ran yesterday. First create a directory to store the phased assembly. 

```bash
mkdir assembly/nphase
# Pairwise alignment of long reads
minimap2 -x ava-ont -t 2 phasing/nphase/scI/Phased/FastQ/reads/scI_0.1_0.01_0.05_0_mergedCluster_1944.fastq.gz phasing/nphase/scI/Phased/FastQ/reads/scI_0.1_0.01_0.05_0_mergedCluster_1944.fastq.gz > assembly/nphase/pairwise_longread_aln_hap1otype1.paf
# Run miniasm
miniasm -f phasing/nphase/scI/Phased/FastQ/reads/scI_0.1_0.01_0.05_0_mergedCluster_1944.fastq.gz assembly/nphase/pairwise_longread_aln_hap1otype1.paf > assembly/nphase/miniasm_assembly_haplotype1.gfa
# Extract fasta sequence from the assembly graph
awk '/^S/{print ">"$2"\n"$3}' assembly/nphase/miniasm_assembly_haplotype1.gfa | fold > assembly/nphase/miniasm_assembly_haplotype1.fasta
```

#### Note that nPhase only clusters the long reads, unlike HAT, so we do not know which short read belong to which haplotype. For that reason, we can not polish the haplotype asseblies.

#### Task: Visualize haplotypes phased by HAT
- To visualize HAT's phasing, we will first align the assembles haplotypes using `Mauve`.
```bash
<insert mauve command here>
```

- Now we can visualize the haplotype alignments in `GenomeView`
```bash
<insert genomeview command here>
```
